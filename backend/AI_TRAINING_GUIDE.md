# AI í•™ìŠµ ë°ì´í„° íŒŒì´í”„ë¼ì¸ ê°€ì´ë“œ

## ê°œìš”

ì €ì¥ëœ ìº”ë“¤ ë°ì´í„° + ê¸°ìˆ ì  ì§€í‘œë¥¼ ê°€ê³µí•˜ì—¬ AI ëª¨ë¸ í•™ìŠµì— ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.

```
[DB: market_candles] â†’ [ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°] â†’ [ë ˆì´ë¸”ë§] â†’ [í•™ìŠµ ë°ì´í„°ì…‹] â†’ [AI ëª¨ë¸ í•™ìŠµ]
```

---

## 1. ë°ì´í„° ì†ŒìŠ¤

### 1.1 ì €ì¥ëœ ìº”ë“¤ ë°ì´í„° (market_candles í…Œì´ë¸”)

```sql
SELECT * FROM market_candles 
WHERE symbol = 'BTCUSDT' AND timeframe = '1h'
ORDER BY open_time DESC
LIMIT 1000;
```

| ì»¬ëŸ¼ | ì„¤ëª… |
|------|------|
| symbol | ê±°ë˜ìŒ (BTCUSDT) |
| timeframe | ì‹œê°„í”„ë ˆì„ (1h, 4h, 1d) |
| open_time | ìº”ë“¤ ì‹œì‘ ì‹œê°„ |
| open, high, low, close | OHLC ê°€ê²© |
| volume | ê±°ë˜ëŸ‰ |
| quote_volume | ê²¬ì  ê±°ë˜ëŸ‰ |
| trades_count | ê±°ë˜ íšŸìˆ˜ |

---

## 2. ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°

### 2.1 ì‚¬ìš© ê°€ëŠ¥í•œ ì§€í‘œ (TechnicalIndicators í´ë˜ìŠ¤)

```python
from app.services.technical_indicators import TechnicalIndicators

# DataFrameì— ëª¨ë“  ì§€í‘œ ì¶”ê°€
df_with_indicators = TechnicalIndicators.calculate_all_indicators(df)
```

**ê³„ì‚°ë˜ëŠ” ì§€í‘œ:**

| ì§€í‘œ | ì»¬ëŸ¼ëª… | ì„¤ëª… |
|------|--------|------|
| RSI | `rsi_14` | ìƒëŒ€ê°•ë„ì§€ìˆ˜ (14ê¸°ê°„) |
| MACD | `macd`, `macd_signal`, `macd_histogram` | ì´ë™í‰ê· ìˆ˜ë ´í™•ì‚° |
| Bollinger Bands | `bb_upper`, `bb_middle`, `bb_lower` | ë³¼ë¦°ì € ë°´ë“œ |
| EMA | `ema_12`, `ema_26`, `ema_50`, `ema_200` | ì§€ìˆ˜ì´ë™í‰ê·  |
| SMA | `sma_20`, `sma_50`, `sma_200` | ë‹¨ìˆœì´ë™í‰ê·  |
| Stochastic | `stoch_k`, `stoch_d` | ìŠ¤í† ìºìŠ¤í‹± |
| ATR | `atr_14` | í‰ê· ì§„í­ |
| OBV | `obv` | ê±°ë˜ëŸ‰ ê¸°ë°˜ ì§€í‘œ |
| ADX | `adx` | ì¶”ì„¸ ê°•ë„ |

---

## 3. í•™ìŠµ ë°ì´í„° ìƒì„±

### 3.1 ë°ì´í„° ê°€ê³µ ìŠ¤í¬ë¦½íŠ¸

```python
# backend/scripts/prepare_training_data.py

import asyncio
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from sqlalchemy import select
from app.database import AsyncSessionLocal
from app.models.market_data import MarketCandle
from app.services.technical_indicators import TechnicalIndicators

async def load_candles(symbol: str, timeframe: str, limit: int = 5000) -> pd.DataFrame:
    """DBì—ì„œ ìº”ë“¤ ë°ì´í„° ë¡œë“œ"""
    async with AsyncSessionLocal() as session:
        result = await session.execute(
            select(MarketCandle)
            .where(MarketCandle.symbol == symbol)
            .where(MarketCandle.timeframe == timeframe)
            .order_by(MarketCandle.open_time.asc())
            .limit(limit)
        )
        candles = result.scalars().all()
        
        data = [{
            'timestamp': c.open_time,
            'open': float(c.open),
            'high': float(c.high),
            'low': float(c.low),
            'close': float(c.close),
            'volume': float(c.volume),
        } for c in candles]
        
        df = pd.DataFrame(data)
        df.set_index('timestamp', inplace=True)
        return df

def add_technical_indicators(df: pd.DataFrame) -> pd.DataFrame:
    """ê¸°ìˆ ì  ì§€í‘œ ì¶”ê°€"""
    return TechnicalIndicators.calculate_all_indicators(df)

def create_labels(df: pd.DataFrame, future_periods: int = 5, threshold: float = 0.02) -> pd.DataFrame:
    """
    ë ˆì´ë¸” ìƒì„± (ë¯¸ë˜ ê°€ê²© ë³€í™” ê¸°ë°˜)
    
    Args:
        future_periods: ëª‡ ìº”ë“¤ í›„ ê°€ê²©ì„ ë³¼ ê²ƒì¸ì§€
        threshold: ìƒìŠ¹/í•˜ë½ íŒë‹¨ ê¸°ì¤€ (2% = 0.02)
    
    Labels:
        2: STRONG_BUY (5% ì´ìƒ ìƒìŠ¹)
        1: BUY (2% ì´ìƒ ìƒìŠ¹)
        0: HOLD (-2% ~ 2%)
        -1: SELL (2% ì´ìƒ í•˜ë½)
        -2: STRONG_SELL (5% ì´ìƒ í•˜ë½)
    """
    df = df.copy()
    
    # ë¯¸ë˜ ê°€ê²©
    df['future_close'] = df['close'].shift(-future_periods)
    
    # ê°€ê²© ë³€í™”ìœ¨
    df['price_change'] = (df['future_close'] - df['close']) / df['close']
    
    # ë ˆì´ë¸” ìƒì„±
    def get_label(change):
        if pd.isna(change):
            return np.nan
        if change >= 0.05:
            return 2  # STRONG_BUY
        elif change >= threshold:
            return 1  # BUY
        elif change <= -0.05:
            return -2  # STRONG_SELL
        elif change <= -threshold:
            return -1  # SELL
        else:
            return 0  # HOLD
    
    df['label'] = df['price_change'].apply(get_label)
    
    return df

def create_features(df: pd.DataFrame) -> pd.DataFrame:
    """
    í•™ìŠµìš© í”¼ì²˜ ìƒì„±
    """
    df = df.copy()
    
    # ê°€ê²© ê´€ë ¨ í”¼ì²˜
    df['price_change_1'] = df['close'].pct_change(1)
    df['price_change_5'] = df['close'].pct_change(5)
    df['price_change_10'] = df['close'].pct_change(10)
    
    # ê±°ë˜ëŸ‰ ê´€ë ¨ í”¼ì²˜
    df['volume_change_1'] = df['volume'].pct_change(1)
    df['volume_ma_ratio'] = df['volume'] / df['volume'].rolling(20).mean()
    
    # ê°€ê²© ìœ„ì¹˜ í”¼ì²˜
    df['price_position'] = (df['close'] - df['low']) / (df['high'] - df['low'] + 1e-8)
    
    # ë³¼ë¦°ì € ë°´ë“œ ìœ„ì¹˜
    if 'bb_upper' in df.columns and 'bb_lower' in df.columns:
        df['bb_position'] = (df['close'] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'] + 1e-8)
    
    # RSI ì •ê·œí™”
    if 'rsi_14' in df.columns:
        df['rsi_normalized'] = df['rsi_14'] / 100
    
    # MACD ì •ê·œí™”
    if 'macd' in df.columns:
        df['macd_normalized'] = df['macd'] / df['close'] * 100
    
    # EMA í¬ë¡œìŠ¤ í”¼ì²˜
    if 'ema_12' in df.columns and 'ema_26' in df.columns:
        df['ema_cross'] = (df['ema_12'] - df['ema_26']) / df['close'] * 100
    
    return df

async def prepare_training_dataset(
    symbol: str = 'BTCUSDT',
    timeframe: str = '1h',
    limit: int = 5000,
    future_periods: int = 5,
    threshold: float = 0.02
) -> pd.DataFrame:
    """
    í•™ìŠµ ë°ì´í„°ì…‹ ì¤€ë¹„
    """
    print(f"ğŸ“Š Loading candles for {symbol} {timeframe}...")
    df = await load_candles(symbol, timeframe, limit)
    print(f"   Loaded {len(df)} candles")
    
    print("ğŸ“ˆ Adding technical indicators...")
    df = add_technical_indicators(df)
    
    print("ğŸ·ï¸ Creating labels...")
    df = create_labels(df, future_periods, threshold)
    
    print("ğŸ”§ Creating features...")
    df = create_features(df)
    
    # NaN ì œê±°
    df = df.dropna()
    print(f"âœ… Final dataset: {len(df)} samples")
    
    # ë ˆì´ë¸” ë¶„í¬ ì¶œë ¥
    print("\nğŸ“Š Label distribution:")
    print(df['label'].value_counts().sort_index())
    
    return df

def save_dataset(df: pd.DataFrame, filename: str):
    """ë°ì´í„°ì…‹ ì €ì¥"""
    df.to_csv(filename, index=True)
    print(f"ğŸ’¾ Saved to {filename}")

# ì‹¤í–‰
if __name__ == "__main__":
    df = asyncio.run(prepare_training_dataset(
        symbol='BTCUSDT',
        timeframe='1h',
        limit=10000,
        future_periods=5,
        threshold=0.02
    ))
    
    save_dataset(df, 'data/btcusdt_1h_training.csv')
```

### 3.2 í”¼ì²˜ ëª©ë¡

| ì¹´í…Œê³ ë¦¬ | í”¼ì²˜ | ì„¤ëª… |
|----------|------|------|
| **ê°€ê²©** | `open`, `high`, `low`, `close` | OHLC |
| **ë³€í™”ìœ¨** | `price_change_1`, `price_change_5`, `price_change_10` | 1/5/10 ìº”ë“¤ ì „ ëŒ€ë¹„ ë³€í™”ìœ¨ |
| **ê±°ë˜ëŸ‰** | `volume`, `volume_change_1`, `volume_ma_ratio` | ê±°ë˜ëŸ‰ ê´€ë ¨ |
| **RSI** | `rsi_14`, `rsi_normalized` | ê³¼ë§¤ìˆ˜/ê³¼ë§¤ë„ |
| **MACD** | `macd`, `macd_signal`, `macd_histogram`, `macd_normalized` | ì¶”ì„¸ |
| **ë³¼ë¦°ì €** | `bb_upper`, `bb_middle`, `bb_lower`, `bb_position` | ë³€ë™ì„± |
| **ì´ë™í‰ê· ** | `ema_12`, `ema_26`, `ema_50`, `ema_200`, `ema_cross` | ì¶”ì„¸ |
| **ìŠ¤í† ìºìŠ¤í‹±** | `stoch_k`, `stoch_d` | ëª¨ë©˜í…€ |
| **ê¸°íƒ€** | `atr_14`, `adx`, `obv` | ë³€ë™ì„±, ì¶”ì„¸ê°•ë„, ê±°ë˜ëŸ‰ |

---

## 4. AI ëª¨ë¸ í•™ìŠµ

### 4.1 ê°„ë‹¨í•œ ë¶„ë¥˜ ëª¨ë¸ (XGBoost)

```python
# backend/scripts/train_model.py

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix
import xgboost as xgb
import joblib

def load_dataset(filename: str) -> pd.DataFrame:
    """ë°ì´í„°ì…‹ ë¡œë“œ"""
    return pd.read_csv(filename, index_col=0, parse_dates=True)

def prepare_features_and_labels(df: pd.DataFrame):
    """í”¼ì²˜ì™€ ë ˆì´ë¸” ë¶„ë¦¬"""
    
    # í•™ìŠµì— ì‚¬ìš©í•  í”¼ì²˜ ì»¬ëŸ¼
    feature_columns = [
        # ê¸°ìˆ ì  ì§€í‘œ
        'rsi_14', 'macd', 'macd_signal', 'macd_histogram',
        'bb_position', 'stoch_k', 'stoch_d', 'atr_14', 'adx',
        
        # ê°€ê²© ë³€í™”
        'price_change_1', 'price_change_5', 'price_change_10',
        
        # ê±°ë˜ëŸ‰
        'volume_change_1', 'volume_ma_ratio',
        
        # ì¶”ê°€ í”¼ì²˜
        'ema_cross', 'rsi_normalized', 'macd_normalized', 'price_position'
    ]
    
    # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
    available_features = [col for col in feature_columns if col in df.columns]
    
    X = df[available_features].values
    y = df['label'].values
    
    return X, y, available_features

def train_xgboost(X_train, y_train, X_test, y_test):
    """XGBoost ëª¨ë¸ í•™ìŠµ"""
    
    # ë ˆì´ë¸”ì„ 0ë¶€í„° ì‹œì‘í•˜ë„ë¡ ì¡°ì • (-2,-1,0,1,2 â†’ 0,1,2,3,4)
    y_train_adjusted = y_train + 2
    y_test_adjusted = y_test + 2
    
    model = xgb.XGBClassifier(
        n_estimators=100,
        max_depth=6,
        learning_rate=0.1,
        objective='multi:softmax',
        num_class=5,
        eval_metric='mlogloss',
        use_label_encoder=False,
        random_state=42
    )
    
    model.fit(
        X_train, y_train_adjusted,
        eval_set=[(X_test, y_test_adjusted)],
        early_stopping_rounds=10,
        verbose=True
    )
    
    return model

def evaluate_model(model, X_test, y_test, feature_names):
    """ëª¨ë¸ í‰ê°€"""
    y_test_adjusted = y_test + 2
    y_pred = model.predict(X_test)
    
    # ë ˆì´ë¸” ë§¤í•‘
    label_names = ['STRONG_SELL', 'SELL', 'HOLD', 'BUY', 'STRONG_BUY']
    
    print("\nğŸ“Š Classification Report:")
    print(classification_report(y_test_adjusted, y_pred, target_names=label_names))
    
    print("\nğŸ“Š Confusion Matrix:")
    print(confusion_matrix(y_test_adjusted, y_pred))
    
    # í”¼ì²˜ ì¤‘ìš”ë„
    print("\nğŸ“Š Feature Importance:")
    importance = model.feature_importances_
    for name, imp in sorted(zip(feature_names, importance), key=lambda x: x[1], reverse=True):
        print(f"  {name}: {imp:.4f}")

def main():
    # 1. ë°ì´í„° ë¡œë“œ
    print("ğŸ“‚ Loading dataset...")
    df = load_dataset('data/btcusdt_1h_training.csv')
    print(f"   Loaded {len(df)} samples")
    
    # 2. í”¼ì²˜/ë ˆì´ë¸” ë¶„ë¦¬
    print("ğŸ”§ Preparing features...")
    X, y, feature_names = prepare_features_and_labels(df)
    print(f"   Features: {len(feature_names)}")
    
    # 3. ì •ê·œí™”
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # 4. í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„ë¦¬
    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y, test_size=0.2, random_state=42, shuffle=False
    )
    print(f"   Train: {len(X_train)}, Test: {len(X_test)}")
    
    # 5. ëª¨ë¸ í•™ìŠµ
    print("\nğŸš€ Training XGBoost model...")
    model = train_xgboost(X_train, y_train, X_test, y_test)
    
    # 6. í‰ê°€
    evaluate_model(model, X_test, y_test, feature_names)
    
    # 7. ëª¨ë¸ ì €ì¥
    print("\nğŸ’¾ Saving model...")
    joblib.dump(model, 'models/xgboost_btcusdt_1h.joblib')
    joblib.dump(scaler, 'models/scaler_btcusdt_1h.joblib')
    joblib.dump(feature_names, 'models/features_btcusdt_1h.joblib')
    print("âœ… Model saved!")

if __name__ == "__main__":
    main()
```

### 4.2 LSTM ë”¥ëŸ¬ë‹ ëª¨ë¸

```python
# backend/scripts/train_lstm.py

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

def create_sequences(X, y, sequence_length=50):
    """ì‹œê³„ì—´ ì‹œí€€ìŠ¤ ìƒì„±"""
    X_seq, y_seq = [], []
    for i in range(sequence_length, len(X)):
        X_seq.append(X[i-sequence_length:i])
        y_seq.append(y[i])
    return np.array(X_seq), np.array(y_seq)

def build_lstm_model(input_shape, num_classes=5):
    """LSTM ëª¨ë¸ êµ¬ì¶•"""
    model = Sequential([
        LSTM(128, return_sequences=True, input_shape=input_shape),
        Dropout(0.2),
        BatchNormalization(),
        
        LSTM(64, return_sequences=True),
        Dropout(0.2),
        BatchNormalization(),
        
        LSTM(32, return_sequences=False),
        Dropout(0.2),
        
        Dense(32, activation='relu'),
        Dense(num_classes, activation='softmax')
    ])
    
    model.compile(
        optimizer='adam',
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    
    return model

def main():
    # ë°ì´í„° ë¡œë“œ
    df = pd.read_csv('data/btcusdt_1h_training.csv', index_col=0, parse_dates=True)
    
    # í”¼ì²˜ ì„ íƒ
    feature_columns = [
        'rsi_14', 'macd', 'macd_signal', 'stoch_k', 'stoch_d',
        'bb_position', 'ema_cross', 'price_change_1', 'volume_ma_ratio'
    ]
    
    X = df[feature_columns].values
    y = (df['label'].values + 2).astype(int)  # 0-4ë¡œ ë³€í™˜
    
    # ì •ê·œí™”
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # ì‹œí€€ìŠ¤ ìƒì„±
    sequence_length = 50
    X_seq, y_seq = create_sequences(X_scaled, y, sequence_length)
    
    # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„ë¦¬
    X_train, X_test, y_train, y_test = train_test_split(
        X_seq, y_seq, test_size=0.2, shuffle=False
    )
    
    # ëª¨ë¸ êµ¬ì¶•
    model = build_lstm_model(
        input_shape=(sequence_length, len(feature_columns)),
        num_classes=5
    )
    
    # ì½œë°±
    callbacks = [
        EarlyStopping(patience=10, restore_best_weights=True),
        ModelCheckpoint('models/lstm_best.h5', save_best_only=True)
    ]
    
    # í•™ìŠµ
    history = model.fit(
        X_train, y_train,
        validation_data=(X_test, y_test),
        epochs=100,
        batch_size=32,
        callbacks=callbacks
    )
    
    # í‰ê°€
    loss, accuracy = model.evaluate(X_test, y_test)
    print(f"\nâœ… Test Accuracy: {accuracy:.4f}")
    
    # ëª¨ë¸ ì €ì¥
    model.save('models/lstm_btcusdt_1h.h5')

if __name__ == "__main__":
    main()
```

---

## 5. í•™ìŠµëœ ëª¨ë¸ ì„œë¹„ìŠ¤ ì—°ë™

### 5.1 ì˜ˆì¸¡ ì„œë¹„ìŠ¤

```python
# backend/app/services/trained_model_service.py

import joblib
import numpy as np
import pandas as pd
from typing import Dict, Any, List
from app.services.technical_indicators import TechnicalIndicators

class TrainedModelService:
    def __init__(self, model_path: str, scaler_path: str, features_path: str):
        self.model = joblib.load(model_path)
        self.scaler = joblib.load(scaler_path)
        self.feature_names = joblib.load(features_path)
        
        # ë ˆì´ë¸” ë§¤í•‘
        self.label_map = {
            0: ('STRONG_SELL', -2),
            1: ('SELL', -1),
            2: ('HOLD', 0),
            3: ('BUY', 1),
            4: ('STRONG_BUY', 2)
        }
    
    def predict(self, candles: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        ìº”ë“¤ ë°ì´í„°ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰
        """
        # DataFrame ìƒì„±
        df = pd.DataFrame(candles)
        if 'timestamp' in df.columns:
            df.set_index('timestamp', inplace=True)
        
        # ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
        df = TechnicalIndicators.calculate_all_indicators(df)
        
        # ì¶”ê°€ í”¼ì²˜ ìƒì„±
        df = self._create_features(df)
        
        # í”¼ì²˜ ì¶”ì¶œ
        X = df[self.feature_names].iloc[-1:].values
        
        # ì •ê·œí™”
        X_scaled = self.scaler.transform(X)
        
        # ì˜ˆì¸¡
        pred_class = self.model.predict(X_scaled)[0]
        pred_proba = self.model.predict_proba(X_scaled)[0]
        
        label_name, label_value = self.label_map[pred_class]
        confidence = float(pred_proba[pred_class])
        
        return {
            'signal': label_name,
            'signal_value': label_value,
            'confidence': confidence,
            'probabilities': {
                self.label_map[i][0]: float(p) 
                for i, p in enumerate(pred_proba)
            }
        }
    
    def _create_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """ì¶”ê°€ í”¼ì²˜ ìƒì„±"""
        df = df.copy()
        
        df['price_change_1'] = df['close'].pct_change(1)
        df['price_change_5'] = df['close'].pct_change(5)
        df['price_change_10'] = df['close'].pct_change(10)
        df['volume_change_1'] = df['volume'].pct_change(1)
        df['volume_ma_ratio'] = df['volume'] / df['volume'].rolling(20).mean()
        df['price_position'] = (df['close'] - df['low']) / (df['high'] - df['low'] + 1e-8)
        
        if 'bb_upper' in df.columns and 'bb_lower' in df.columns:
            df['bb_position'] = (df['close'] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'] + 1e-8)
        
        if 'rsi_14' in df.columns:
            df['rsi_normalized'] = df['rsi_14'] / 100
        
        if 'macd' in df.columns:
            df['macd_normalized'] = df['macd'] / df['close'] * 100
        
        if 'ema_12' in df.columns and 'ema_26' in df.columns:
            df['ema_cross'] = (df['ema_12'] - df['ema_26']) / df['close'] * 100
        
        return df
```

---

## 6. ì‹¤í–‰ ìˆœì„œ

```bash
# 1. ë°ì´í„° ì¤€ë¹„
cd backend
python scripts/prepare_training_data.py

# 2. ëª¨ë¸ í•™ìŠµ (XGBoost)
python scripts/train_model.py

# 3. (ì„ íƒ) LSTM ëª¨ë¸ í•™ìŠµ
python scripts/train_lstm.py

# 4. ì„œë²„ì—ì„œ í•™ìŠµëœ ëª¨ë¸ ì‚¬ìš©
# configì— ëª¨ë¸ ê²½ë¡œ ì„¤ì • í›„ ì„œë²„ ì¬ì‹œì‘
```

---

## 7. íŒ

### 7.1 ë°ì´í„° í’ˆì§ˆ
- **ì¶©ë¶„í•œ ë°ì´í„°**: ìµœì†Œ 1000ê°œ ì´ìƒì˜ ìº”ë“¤ ê¶Œì¥
- **ë‹¤ì–‘í•œ ì‹œì¥ ìƒí™©**: ìƒìŠ¹ì¥, í•˜ë½ì¥, íš¡ë³´ì¥ ëª¨ë‘ í¬í•¨
- **ì´ìƒì¹˜ ì²˜ë¦¬**: ê·¹ë‹¨ì ì¸ ë³€ë™ ë°ì´í„° ì œê±°

### 7.2 í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
- **ì‹œê°„ í”¼ì²˜**: ìš”ì¼, ì‹œê°„ëŒ€ ì¶”ê°€
- **ì™¸ë¶€ ë°ì´í„°**: ë¹„íŠ¸ì½”ì¸ ë„ë¯¸ë„ŒìŠ¤, ê³µí¬/íƒìš• ì§€ìˆ˜
- **ìƒê´€ê´€ê³„**: ë‹¤ë¥¸ ì½”ì¸ ê°€ê²© ë³€í™”

### 7.3 ëª¨ë¸ ê°œì„ 
- **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹**: GridSearchCV ì‚¬ìš©
- **ì•™ìƒë¸”**: ì—¬ëŸ¬ ëª¨ë¸ ì¡°í•©
- **ì‹œê³„ì—´ ê²€ì¦**: TimeSeriesSplit ì‚¬ìš©

### 7.4 ì‹¤ì „ ì ìš©
- **ë°±í…ŒìŠ¤íŒ…**: ê³¼ê±° ë°ì´í„°ë¡œ ì „ëµ ê²€ì¦
- **ìŠ¬ë¦¬í”¼ì§€/ìˆ˜ìˆ˜ë£Œ**: ì‹¤ì œ ê±°ë˜ ë¹„ìš© ë°˜ì˜
- **ë¦¬ìŠ¤í¬ ê´€ë¦¬**: í¬ì§€ì…˜ í¬ê¸° ì¡°ì ˆ




