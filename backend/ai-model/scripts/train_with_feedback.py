"""
í”¼ë“œë°± ê¸°ë°˜ ëª¨ë¸ ì¬í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
- ì‹¤ì œ ê±°ë˜ ê²°ê³¼ë¥¼ í•™ìŠµ ë°ì´í„°ë¡œ í™œìš©
- ê¸°ì¡´ ëª¨ë¸ì„ fine-tuning
"""

import os
import sys
import argparse
import pandas as pd
import numpy as np
import requests
import joblib

AI_MODEL_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, AI_MODEL_DIR)

from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score


def fetch_feedback_data(api_url: str, symbol: str = None, timeframe: str = '5m') -> pd.DataFrame:
    """APIì—ì„œ í”¼ë“œë°± ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
    params = {'timeframe': timeframe}
    if symbol:
        params['symbol'] = symbol
    
    response = requests.get(f"{api_url}/api/feedback/training-data", params=params)
    
    if response.status_code != 200:
        print(f"âŒ Failed to fetch feedback data: {response.status_code}")
        return pd.DataFrame()
    
    result = response.json()
    print(f"âœ… Fetched {result['count']} feedback records")
    
    if result['count'] == 0:
        return pd.DataFrame()
    
    return pd.DataFrame(result['data'])


def combine_with_original_data(feedback_df: pd.DataFrame, original_path: str) -> pd.DataFrame:
    """í”¼ë“œë°± ë°ì´í„°ì™€ ì›ë³¸ í•™ìŠµ ë°ì´í„° ê²°í•©"""
    
    # ì›ë³¸ ë°ì´í„° ë¡œë“œ
    if os.path.exists(original_path):
        original_df = pd.read_csv(original_path, index_col=0)
        print(f"ğŸ“Š Original data: {len(original_df)} samples")
    else:
        original_df = pd.DataFrame()
        print("âš ï¸ No original data found")
    
    # í”¼ë“œë°± ë°ì´í„°ì—ì„œ í•™ìŠµ í”¼ì²˜ ì¶”ì¶œ
    feedback_features = []
    for _, row in feedback_df.iterrows():
        if pd.notna(row.get('actual_label')) and row['actual_label'] >= 0:
            # ì§€í‘œ ìŠ¤ëƒ…ìƒ·ì´ ìˆìœ¼ë©´ ì‚¬ìš©
            feature_row = dict(row)
            feature_row['label'] = row['actual_label']  # ì‹¤ì œ ê²°ê³¼ê°€ ë ˆì´ë¸”
            feedback_features.append(feature_row)
    
    feedback_train_df = pd.DataFrame(feedback_features)
    print(f"ğŸ“ Feedback data with labels: {len(feedback_train_df)} samples")
    
    # ê³µí†µ í”¼ì²˜ë§Œ ì‚¬ìš©í•˜ì—¬ ê²°í•©
    if len(original_df) > 0 and len(feedback_train_df) > 0:
        common_cols = list(set(original_df.columns) & set(feedback_train_df.columns))
        combined = pd.concat([
            original_df[common_cols],
            feedback_train_df[common_cols]
        ], ignore_index=True)
        print(f"ğŸ”— Combined data: {len(combined)} samples")
        return combined
    elif len(feedback_train_df) > 0:
        return feedback_train_df
    else:
        return original_df


def fine_tune_xgboost(
    model_path: str,
    data: pd.DataFrame,
    feature_cols: list,
    output_path: str
):
    """ê¸°ì¡´ XGBoost ëª¨ë¸ fine-tuning"""
    import xgboost as xgb
    
    # ê¸°ì¡´ ëª¨ë¸ ë¡œë“œ
    if os.path.exists(model_path):
        print(f"ğŸ“¥ Loading existing model: {model_path}")
        model = joblib.load(model_path)
    else:
        print("âš ï¸ No existing model, creating new one")
        model = xgb.XGBClassifier(
            n_estimators=200,
            max_depth=6,
            learning_rate=0.05,
            objective='binary:logistic',
            random_state=42
        )
    
    # í”¼ì²˜ ì¤€ë¹„
    available_features = [col for col in feature_cols if col in data.columns]
    X = data[available_features].fillna(0).values
    y = data['label'].values
    
    # ë ˆì´ë¸”ì„ 0, 1ë¡œ ë³€í™˜
    unique_labels = np.unique(y)
    print(f"ğŸ“Š Labels in data: {unique_labels}")
    
    if len(unique_labels) < 2:
        print("âŒ Need at least 2 classes for training")
        return False
    
    # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    print(f"\nğŸ¯ Fine-tuning with {len(X_train)} samples...")
    
    # Fine-tuning (ê¸°ì¡´ ëª¨ë¸ ìœ„ì— ì¶”ê°€ í•™ìŠµ)
    model.fit(
        X_train, y_train,
        eval_set=[(X_test, y_test)],
        verbose=True
    )
    
    # í‰ê°€
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    
    print(f"\nğŸ“Š Fine-tuned Model Accuracy: {accuracy*100:.2f}%")
    print("\nClassification Report:")
    print(classification_report(y_test, y_pred))
    
    # ëª¨ë¸ ì €ì¥
    joblib.dump(model, output_path)
    print(f"\nâœ… Fine-tuned model saved: {output_path}")
    
    return True


def main():
    parser = argparse.ArgumentParser(description='Fine-tune model with feedback data')
    parser.add_argument('--api', type=str, default='http://localhost:8000', help='Backend API URL')
    parser.add_argument('--symbol', type=str, default=None, help='Symbol to filter (optional)')
    parser.add_argument('--timeframe', type=str, default='5m', help='Timeframe')
    parser.add_argument('--original-data', type=str, default=None, help='Original training data CSV')
    parser.add_argument('--model', type=str, required=True, help='Existing model path')
    parser.add_argument('--output', type=str, required=True, help='Output model path')
    
    args = parser.parse_args()
    
    print("="*60)
    print("ğŸ§  Feedback-based Model Fine-tuning")
    print("="*60)
    
    # 1. í”¼ë“œë°± ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    print("\n[1/4] Fetching feedback data...")
    feedback_df = fetch_feedback_data(args.api, args.symbol, args.timeframe)
    
    if len(feedback_df) == 0:
        print("âŒ No feedback data available. Trade more and record feedback!")
        return
    
    # 2. ì›ë³¸ ë°ì´í„°ì™€ ê²°í•©
    print("\n[2/4] Combining with original data...")
    if args.original_data:
        combined_df = combine_with_original_data(feedback_df, args.original_data)
    else:
        combined_df = feedback_df
        combined_df['label'] = combined_df['actual_label']
    
    if len(combined_df) < 50:
        print(f"âš ï¸ Only {len(combined_df)} samples. Recommend at least 50 for reliable training.")
    
    # 3. í”¼ì²˜ ëª©ë¡ (ëª¨ë¸ì—ì„œ ì‚¬ìš©í•˜ëŠ” í”¼ì²˜ë“¤)
    feature_cols = [
        'rsi_14', 'macd', 'macd_signal', 'macd_histogram',
        'bb_position', 'stoch_k', 'stoch_d', 'atr_14', 'adx',
        'price_change_1', 'price_change_5', 'price_change_10',
        'volume_change_1', 'volume_ma_ratio', 'volume_spike',
        'obv_slope', 'mfi_normalized', 'williams_r',
        'pump_6', 'drawdown_from_high_12', 'volatility_spike',
        'ai_confidence'  # AI ìì²´ ì‹ ë¢°ë„ë„ í”¼ì²˜ë¡œ!
    ]
    
    # 4. Fine-tuning
    print("\n[3/4] Fine-tuning model...")
    success = fine_tune_xgboost(
        model_path=args.model,
        data=combined_df,
        feature_cols=feature_cols,
        output_path=args.output
    )
    
    if success:
        print("\n[4/4] âœ… Fine-tuning complete!")
        print(f"   New model: {args.output}")
        print("\nğŸ’¡ Tip: Copy to ai-model/models/ and restart backend to use")
    else:
        print("\nâŒ Fine-tuning failed")


if __name__ == '__main__':
    main()

