"""
Unified LSTM Model with Asset Embedding
ë‹¨ì¼ ëª¨ë¸ë¡œ ì—¬ëŸ¬ ìì‚°(ì½”ì¸, ì£¼ì‹)ì„ í•™ìŠµí•˜ê³  ì˜ˆì¸¡

Architecture:
- Input 1: Time Series (60 candles Ã— features)
- Input 2: Asset ID (embedded as vector)
- LSTM Layer: Process time series
- Concatenate: LSTM output + Asset embedding
- Output: Classification (BUY/HOLD/SELL)
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Tuple


class UnifiedLSTMModel(nn.Module):
    """
    í†µí•© LSTM ëª¨ë¸ (Asset Embedding í¬í•¨)

    Args:
        num_assets: ì´ ìì‚° ê°œìˆ˜ (embedding lookup table í¬ê¸°)
        embedding_dim: Asset embedding ë²¡í„° ì°¨ì›
        num_features: ì…ë ¥ í”¼ì²˜ ê°œìˆ˜
        hidden_size: LSTM hidden state í¬ê¸°
        num_classes: ì¶œë ¥ í´ë˜ìŠ¤ ê°œìˆ˜ (2, 3, 5)
        num_layers: LSTM ë ˆì´ì–´ ê°œìˆ˜
        dropout: Dropout ë¹„ìœ¨ (ê³¼ì í•© ë°©ì§€)
        bidirectional: ì–‘ë°©í–¥ LSTM ì‚¬ìš© ì—¬ë¶€
    """

    def __init__(
        self,
        num_assets: int,
        embedding_dim: int = 16,
        num_features: int = 100,
        hidden_size: int = 64,
        num_classes: int = 3,
        num_layers: int = 2,
        dropout: float = 0.3,
        bidirectional: bool = False
    ):
        super(UnifiedLSTMModel, self).__init__()

        self.num_assets = num_assets
        self.embedding_dim = embedding_dim
        self.num_features = num_features
        self.hidden_size = hidden_size
        self.num_classes = num_classes
        self.num_layers = num_layers
        self.bidirectional = bidirectional

        # ===== Asset Embedding Layer =====
        # ìì‚° IDë¥¼ ë²¡í„°ë¡œ ë³€í™˜ (í•™ìŠµ ê°€ëŠ¥í•œ lookup table)
        self.asset_embedding = nn.Embedding(
            num_embeddings=num_assets,
            embedding_dim=embedding_dim,
            padding_idx=None
        )

        # ===== Time Series Processing: LSTM =====
        self.lstm = nn.LSTM(
            input_size=num_features,
            hidden_size=hidden_size,
            num_layers=num_layers,
            batch_first=True,
            dropout=dropout if num_layers > 1 else 0,
            bidirectional=bidirectional
        )

        # LSTM ì¶œë ¥ í¬ê¸° (ì–‘ë°©í–¥ì´ë©´ 2ë°°)
        lstm_output_size = hidden_size * 2 if bidirectional else hidden_size

        # ===== Dropout Layer =====
        self.dropout = nn.Dropout(dropout)

        # ===== Fully Connected Layers =====
        # LSTM ì¶œë ¥ + Asset Embedding ê²°í•©
        combined_size = lstm_output_size + embedding_dim

        self.fc1 = nn.Linear(combined_size, 64)
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, num_classes)

        # Batch Normalization (ì„ íƒì )
        self.bn1 = nn.BatchNorm1d(64)
        self.bn2 = nn.BatchNorm1d(32)

    def forward(
        self,
        time_series: torch.Tensor,
        asset_ids: torch.Tensor
    ) -> torch.Tensor:
        """
        Forward pass

        Args:
            time_series: (batch_size, sequence_length, num_features)
            asset_ids: (batch_size,) - ê° ìƒ˜í”Œì˜ ìì‚° ID

        Returns:
            logits: (batch_size, num_classes)
        """
        batch_size = time_series.size(0)

        # ===== 1. Asset Embedding =====
        # (batch_size,) â†’ (batch_size, embedding_dim)
        asset_embed = self.asset_embedding(asset_ids)

        # ===== 2. LSTM Processing =====
        # LSTM forward: (batch_size, seq_len, num_features) â†’ (batch_size, seq_len, hidden_size)
        lstm_out, (h_n, c_n) = self.lstm(time_series)

        # ë§ˆì§€ë§‰ ì‹œì ì˜ hidden state ì‚¬ìš©
        if self.bidirectional:
            # ì–‘ë°©í–¥ LSTM: forwardì™€ backwardì˜ ë§ˆì§€ë§‰ hidden state ê²°í•©
            h_forward = h_n[-2, :, :]  # (batch_size, hidden_size)
            h_backward = h_n[-1, :, :]  # (batch_size, hidden_size)
            lstm_final = torch.cat([h_forward, h_backward], dim=1)
        else:
            # ë‹¨ë°©í–¥ LSTM: ë§ˆì§€ë§‰ ë ˆì´ì–´ì˜ hidden state
            lstm_final = h_n[-1, :, :]  # (batch_size, hidden_size)

        # Dropout ì ìš©
        lstm_final = self.dropout(lstm_final)

        # ===== 3. Concatenate LSTM + Embedding =====
        # (batch_size, lstm_output_size) + (batch_size, embedding_dim)
        # â†’ (batch_size, lstm_output_size + embedding_dim)
        combined = torch.cat([lstm_final, asset_embed], dim=1)

        # ===== 4. Fully Connected Layers =====
        x = F.relu(self.bn1(self.fc1(combined)))
        x = self.dropout(x)

        x = F.relu(self.bn2(self.fc2(x)))
        x = self.dropout(x)

        logits = self.fc3(x)  # (batch_size, num_classes)

        return logits

    def predict(
        self,
        time_series: torch.Tensor,
        asset_ids: torch.Tensor
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        Prediction (evaluation mode)

        Returns:
            predictions: (batch_size,) - ì˜ˆì¸¡ í´ë˜ìŠ¤ (0, 1, 2, ...)
            probabilities: (batch_size, num_classes) - ê° í´ë˜ìŠ¤ í™•ë¥ 
        """
        self.eval()
        with torch.no_grad():
            logits = self.forward(time_series, asset_ids)
            probabilities = F.softmax(logits, dim=1)
            predictions = torch.argmax(probabilities, dim=1)

        return predictions, probabilities

    def get_embedding(self, asset_id: int) -> torch.Tensor:
        """íŠ¹ì • ìì‚°ì˜ embedding ë²¡í„° ì¡°íšŒ (ë¶„ì„ìš©)"""
        asset_id_tensor = torch.tensor([asset_id], dtype=torch.long)
        return self.asset_embedding(asset_id_tensor).squeeze(0)


# ===== ëª¨ë¸ ìƒì„± í—¬í¼ í•¨ìˆ˜ =====

def create_unified_model(
    num_assets: int,
    num_features: int,
    num_classes: int = 3,
    embedding_dim: int = 16,
    hidden_size: int = 64,
    num_layers: int = 2,
    dropout: float = 0.3,
    bidirectional: bool = False,
    device: str = 'cpu'
) -> UnifiedLSTMModel:
    """
    í†µí•© ëª¨ë¸ ìƒì„±

    Example:
        model = create_unified_model(
            num_assets=200,  # ìµœëŒ€ 200ê°œ ìì‚°
            num_features=100,  # 100ê°œ í”¼ì²˜
            num_classes=3,  # BUY/HOLD/SELL
            embedding_dim=16,
            hidden_size=64
        )
    """
    model = UnifiedLSTMModel(
        num_assets=num_assets,
        embedding_dim=embedding_dim,
        num_features=num_features,
        hidden_size=hidden_size,
        num_classes=num_classes,
        num_layers=num_layers,
        dropout=dropout,
        bidirectional=bidirectional
    )

    model = model.to(device)

    # íŒŒë¼ë¯¸í„° ê°œìˆ˜ ì¶œë ¥
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

    print(f"âœ… Unified LSTM Model created:")
    print(f"   - Total parameters: {total_params:,}")
    print(f"   - Trainable parameters: {trainable_params:,}")
    print(f"   - Device: {device}")

    return model


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    print("ğŸ§ª Testing Unified LSTM Model...")

    # ëª¨ë¸ ìƒì„±
    model = create_unified_model(
        num_assets=200,
        num_features=100,
        num_classes=3,
        embedding_dim=16,
        hidden_size=64
    )

    # ë”ë¯¸ ì…ë ¥ ìƒì„±
    batch_size = 8
    sequence_length = 60
    num_features = 100

    dummy_time_series = torch.randn(batch_size, sequence_length, num_features)
    dummy_asset_ids = torch.randint(0, 200, (batch_size,))

    print(f"\nğŸ“Š Input shapes:")
    print(f"   - Time series: {dummy_time_series.shape}")
    print(f"   - Asset IDs: {dummy_asset_ids.shape}")

    # Forward pass
    logits = model(dummy_time_series, dummy_asset_ids)
    print(f"\nğŸ“ˆ Output shape: {logits.shape}")

    # Prediction
    predictions, probabilities = model.predict(dummy_time_series, dummy_asset_ids)
    print(f"\nğŸ¯ Predictions: {predictions}")
    print(f"   Probabilities shape: {probabilities.shape}")

    # Embedding í™•ì¸
    btc_embedding = model.get_embedding(0)  # BTC = asset_id 0
    print(f"\nğŸª™ BTC Embedding: {btc_embedding[:5]}... (first 5 dims)")

    print("\nâœ… Test passed!")
