"""
ë²¡í„° íŒ¨í„´ ê²€ìƒ‰ ì„œë¹„ìŠ¤
- FAISSë¥¼ ì‚¬ìš©í•œ ê³¼ê±° ìœ ì‚¬ íŒ¨í„´ ê²€ìƒ‰
- 1ë…„ì¹˜ ë°ì´í„°ë¡œ í•™ìŠµ
"""

import numpy as np
import faiss
import pickle
import logging
from typing import List, Dict, Any, Optional, Tuple
from pathlib import Path
from datetime import datetime, timedelta
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select

from app.models.vector_pattern import VectorPattern, VectorSimilarity
from app.services.technical_indicators import TechnicalIndicators

logger = logging.getLogger(__name__)


class VectorPatternService:
    """ë²¡í„° ê¸°ë°˜ íŒ¨í„´ ê²€ìƒ‰"""

    def __init__(self, db: AsyncSession, symbol: str = "BTCUSDT"):
        self.db = db
        self.symbol = symbol
        self.vector_dim = 16  # 16ì°¨ì› ë²¡í„°: MACD(4) + BB(3) + EMA/SMA(4) + Stoch(2) + ATR/Vol(2) + 1
        self.index = None
        self.index_path = Path(f"data/faiss_index_{symbol}.idx")
        self.metadata_path = Path(f"data/faiss_metadata_{symbol}.pkl")
        
        # ì´ˆê¸°í™”
        self._load_or_create_index()

    def _load_or_create_index(self):
        """ê¸°ì¡´ ì¸ë±ìŠ¤ ë¡œë“œ ë˜ëŠ” ìƒˆë¡œ ìƒì„±"""
        try:
            if self.index_path.exists() and self.metadata_path.exists():
                self.index = faiss.read_index(str(self.index_path))
                logger.info(f"âœ… Loaded FAISS index for {self.symbol}")
                return
        except Exception as e:
            logger.warning(f"Failed to load index: {e}")
        
        # ìƒˆ ì¸ë±ìŠ¤ ìƒì„±
        self.index = faiss.IndexFlatL2(self.vector_dim)
        logger.info(f"Created new FAISS index for {self.symbol}")

    async def build_index_from_history(self):
        """ê³¼ê±° 1ë…„ ë°ì´í„°ë¡œ FAISS ì¸ë±ìŠ¤ êµ¬ì¶•"""
        try:
            logger.info(f"ğŸ”¨ Building vector index for {self.symbol} from 1-year history...")
            
            # 1ë…„ ì „ ë°ì´í„° ì¡°íšŒ
            one_year_ago = datetime.now() - timedelta(days=365)
            result = await self.db.execute(
                select(VectorPattern).where(
                    VectorPattern.symbol == self.symbol,
                    VectorPattern.timestamp >= one_year_ago
                ).order_by(VectorPattern.timestamp)
            )
            patterns = result.scalars().all()
            
            if not patterns:
                logger.warning(f"No historical patterns found for {self.symbol}")
                return 0
            
            vectors = []
            metadata = []
            
            for idx, pattern in enumerate(patterns):
                try:
                    # ì§€í‘œë¥¼ ë²¡í„°ë¡œ ë³€í™˜
                    vector = self._indicators_to_vector(pattern.indicators)
                    if vector is not None:
                        vectors.append(vector)
                        metadata.append({
                            'pattern_id': pattern.id,
                            'timestamp': pattern.timestamp.isoformat(),
                            'signal': pattern.signal,
                            'confidence': pattern.confidence,
                            'return_1h': pattern.return_1h,
                            'return_4h': pattern.return_4h,
                            'return_24h': pattern.return_24h,
                        })
                        
                        # FAISS ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
                        pattern.vector_id = len(vectors) - 1
                        self.db.add(pattern)
                
                except Exception as e:
                    logger.warning(f"Error processing pattern {pattern.id}: {e}")
                    continue
            
            if vectors:
                # FAISS ì¸ë±ìŠ¤ì— ë²¡í„° ì¶”ê°€
                vectors_array = np.array(vectors, dtype=np.float32)
                self.index.add(vectors_array)
                
                # ì¸ë±ìŠ¤ì™€ ë©”íƒ€ë°ì´í„° ì €ì¥
                self.index_path.parent.mkdir(exist_ok=True)
                faiss.write_index(self.index, str(self.index_path))
                with open(self.metadata_path, 'wb') as f:
                    pickle.dump(metadata, f)
                
                await self.db.commit()
                
                logger.info(f"âœ… Built index with {len(vectors)} vectors for {self.symbol}")
                return len(vectors)
            
            return 0
            
        except Exception as e:
            logger.error(f"Error building index: {e}")
            await self.db.rollback()
            return 0

    def _indicators_to_vector(self, indicators: Dict[str, Any]) -> Optional[np.ndarray]:
        """
        ê¸°ìˆ ì  ì§€í‘œë¥¼ 16ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜ (ì •ê·œí™”ë¨)
        
        ë²¡í„° êµ¬ì„±:
        [0-3]: MACD ê´€ë ¨ (MACD, Signal, Histogram, Momentum)
        [4-6]: ë³¼ë¦°ì €ë°´ë“œ (Upper, Middle, Lower)
        [7-10]: ì´ë™í‰ê· ì„  (EMA_12, EMA_26, SMA_20, SMA_50)
        [11-12]: ìŠ¤í† ìºìŠ¤í‹± (K, D)
        [13-14]: ATR, Volume
        [15]: RSI (ë©”ì¸ ì§€í‘œ)
        """
        if not indicators:
            return None
        
        try:
            close = indicators.get('close', 1)
            
            # MACD ê´€ë ¨
            macd = indicators.get('macd', 0) or 0
            macd_signal = indicators.get('macd_signal', 0) or 0
            macd_histogram = indicators.get('macd_histogram', 0) or 0
            macd_momentum = macd - macd_signal
            
            # ë³¼ë¦°ì € ë°´ë“œ
            bb_upper = indicators.get('bb_upper', close) or close
            bb_middle = indicators.get('bb_middle', close) or close
            bb_lower = indicators.get('bb_lower', close) or close
            
            # ì´ë™í‰ê· ì„ 
            ema_12 = indicators.get('ema_12', close) or close
            ema_26 = indicators.get('ema_26', close) or close
            sma_20 = indicators.get('sma_20', close) or close
            sma_50 = indicators.get('sma_50', close) or close
            
            # ìŠ¤í† ìºìŠ¤í‹±
            stoch_k = indicators.get('stoch_k', 50) or 50
            stoch_d = indicators.get('stoch_d', 50) or 50
            
            # ATRê³¼ Volume
            atr = indicators.get('atr_14', 0) or 0
            volume = indicators.get('volume', 0) or 0
            
            # RSI
            rsi = indicators.get('rsi_14', 50) or 50
            
            # íŠ¹ì§• ë²¡í„° ìƒì„± ë° ì •ê·œí™”
            features = [
                # MACD ê´€ë ¨ (0-3)
                np.clip(macd / 0.1, -2, 2) / 2,  # MACD
                np.clip(macd_signal / 0.1, -2, 2) / 2,  # Signal
                np.clip(macd_histogram / 0.05, -2, 2) / 2,  # Histogram
                np.clip(macd_momentum / 0.05, -2, 2) / 2,  # Momentum
                
                # ë³¼ë¦°ì €ë°´ë“œ (4-6) - ê°€ê²© ìœ„ì¹˜
                (close - bb_lower) / (bb_upper - bb_lower + 1e-6),  # BB ë‚´ì—ì„œì˜ ìœ„ì¹˜
                (bb_upper - close) / (bb_upper - bb_lower + 1e-6),  # ìƒë‹¨ê¹Œì§€ ê±°ë¦¬ ë¹„ìœ¨
                (close - bb_lower) / (bb_upper - bb_lower + 1e-6),  # í•˜ë‹¨ë¶€í„° ê±°ë¦¬ ë¹„ìœ¨
                
                # ì´ë™í‰ê· ì„  (7-10) - ë¹„ìœ¨ë¡œ ì •ê·œí™”
                (close - ema_12) / (ema_12 + 1e-6),  # Close vs EMA12
                (ema_12 - ema_26) / (ema_26 + 1e-6),  # EMA í¬ë¡œìŠ¤
                (close - sma_20) / (sma_20 + 1e-6),  # Close vs SMA20
                (sma_20 - sma_50) / (sma_50 + 1e-6),  # MA í¬ë¡œìŠ¤
                
                # ìŠ¤í† ìºìŠ¤í‹± (11-12)
                stoch_k / 100,  # 0-1 ì •ê·œí™”
                stoch_d / 100,  # 0-1 ì •ê·œí™”
                
                # ATRê³¼ Volume (13-14)
                np.clip(atr / (close * 0.02), -1, 1),  # ë³€ë™ì„±
                np.clip(volume / 1e8, 0, 2) / 2,  # ê±°ë˜ëŸ‰
                
                # RSI (15) - ë©”ì¸ ì‹ í˜¸
                rsi / 100,  # 0-1 ì •ê·œí™”
            ]
            
            # NaN/Inf ì²´í¬ ë° ë²”ìœ„ ì œí•œ
            features = [
                0 if (f != f or f is None or np.isinf(f)) else np.clip(float(f), -1, 1)
                for f in features
            ]
            
            if len(features) != 16:
                logger.warning(f"Feature count mismatch: {len(features)} != 16")
                return None
            
            return np.array(features, dtype=np.float32)
        
        except Exception as e:
            logger.warning(f"Error converting indicators to vector: {e}")
            return None

    async def find_similar_patterns(
        self,
        current_indicators: Dict[str, Any],
        k: int = 5,
        similarity_threshold: float = 0.75
    ) -> List[Dict[str, Any]]:
        """í˜„ì¬ ì§€í‘œì™€ ìœ ì‚¬í•œ ê³¼ê±° íŒ¨í„´ ê²€ìƒ‰"""
        try:
            if self.index.ntotal == 0:
                logger.warning("FAISS index is empty")
                return []
            
            # í˜„ì¬ ì§€í‘œë¥¼ ë²¡í„°ë¡œ ë³€í™˜
            query_vector = self._indicators_to_vector(current_indicators)
            if query_vector is None:
                return []
            
            # FAISSì—ì„œ ê²€ìƒ‰
            query_array = np.array([query_vector], dtype=np.float32)
            distances, indices = self.index.search(query_array, min(k, self.index.ntotal))
            
            # ë©”íƒ€ë°ì´í„° ë¡œë“œ
            metadata = self._load_metadata()
            if not metadata:
                return []
            
            similar_patterns = []
            for dist, idx in zip(distances[0], indices[0]):
                if idx < 0 or idx >= len(metadata):
                    continue
                
                # ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜ (ë‚®ì„ìˆ˜ë¡ ìœ ì‚¬)
                similarity = 1 / (1 + dist)
                
                if similarity >= similarity_threshold:
                    pattern_data = metadata[idx].copy()
                    pattern_data['similarity'] = float(similarity)
                    similar_patterns.append(pattern_data)
            
            logger.info(f"Found {len(similar_patterns)} similar patterns (threshold: {similarity_threshold})")
            return similar_patterns
        
        except Exception as e:
            logger.error(f"Error finding similar patterns: {e}")
            return []

    def _load_metadata(self) -> Optional[List[Dict]]:
        """ì €ì¥ëœ ë©”íƒ€ë°ì´í„° ë¡œë“œ"""
        try:
            if self.metadata_path.exists():
                with open(self.metadata_path, 'rb') as f:
                    return pickle.load(f)
        except Exception as e:
            logger.warning(f"Error loading metadata: {e}")
        return None

    async def boost_signal_with_patterns(
        self,
        current_signal: str,
        current_confidence: float,
        current_indicators: Dict[str, Any],
        k: int = 5
    ) -> Tuple[str, float, Dict[str, Any]]:
        """
        ê³¼ê±° ìœ ì‚¬ íŒ¨í„´ìœ¼ë¡œ ì‹ í˜¸ ê°•í™”
        
        Returns:
            (boosted_signal, boosted_confidence, pattern_analysis)
        """
        try:
            # ìœ ì‚¬ íŒ¨í„´ ê²€ìƒ‰
            similar_patterns = await self.find_similar_patterns(
                current_indicators,
                k=k,
                similarity_threshold=0.75
            )
            
            if not similar_patterns:
                return current_signal, current_confidence, {'similar_count': 0}
            
            # ìœ ì‚¬ íŒ¨í„´ì˜ ìˆ˜ìµë¥  ë¶„ì„
            avg_return_1h = np.mean([p.get('return_1h', 0) or 0 for p in similar_patterns])
            avg_return_4h = np.mean([p.get('return_4h', 0) or 0 for p in similar_patterns])
            
            # ìˆ˜ìµë¥ ì´ ì–‘ìˆ˜ë©´ ì‹ í˜¸ ê°•í™”
            boost_amount = 0
            if avg_return_1h > 0:
                boost_amount += min(avg_return_1h / 100, 0.15)  # ìµœëŒ€ +15%
            if avg_return_4h > 0:
                boost_amount += min(avg_return_4h / 100, 0.15)  # ìµœëŒ€ +15%
            
            boosted_confidence = min(current_confidence + boost_amount, 0.95)
            
            # ì‹ í˜¸ ë³€ê²½ ì—¬ë¶€ íŒë‹¨
            boosted_signal = current_signal
            if boosted_confidence > 0.7:
                if current_signal == "SELL" and avg_return_1h > 1:
                    boosted_signal = "HOLD"  # SELL â†’ HOLDë¡œ ì™„í™”
                elif current_signal == "HOLD" and (avg_return_1h > 0.5 or avg_return_4h > 1):
                    boosted_signal = "BUY"  # HOLD â†’ BUYë¡œ ê°•í™”
            
            logger.info(
                f"âœ… Signal boosted: {current_signal}({current_confidence:.2f}) "
                f"â†’ {boosted_signal}({boosted_confidence:.2f})"
            )
            
            return boosted_signal, boosted_confidence, {
                'similar_count': len(similar_patterns),
                'avg_return_1h': float(avg_return_1h),
                'avg_return_4h': float(avg_return_4h),
                'boost_amount': float(boost_amount),
                'similar_patterns': similar_patterns[:3]  # ìƒìœ„ 3ê°œë§Œ ë°˜í™˜
            }
        
        except Exception as e:
            logger.error(f"Error boosting signal: {e}")
            return current_signal, current_confidence, {'error': str(e)}
