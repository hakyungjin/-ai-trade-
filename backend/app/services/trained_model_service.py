"""
í•™ìŠµëœ ëª¨ë¸ ì˜ˆì¸¡ ì„œë¹„ìŠ¤
ì €ì¥ëœ XGBoost/LSTM ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬ ì‹¤ì‹œê°„ ì˜ˆì¸¡ ìˆ˜í–‰

í†µí•© í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ëª¨ë“ˆ(unified_feature_engineering)ì„ ì‚¬ìš©í•˜ì—¬
í•™ìŠµ/ì¶”ë¡  ê°„ í”¼ì²˜ ì¼ê´€ì„± ë³´ì¥
"""

import os
import logging
import numpy as np
import pandas as pd
from typing import Dict, Any, List, Optional
from app.services.technical_indicators import TechnicalIndicators
from app.services.unified_feature_engineering import compute_all_features

logger = logging.getLogger(__name__)


class TrainedModelService:
    """í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•œ ì˜ˆì¸¡ ì„œë¹„ìŠ¤"""
    
    # 2í´ë˜ìŠ¤ ë ˆì´ë¸” ë§¤í•‘ (íš¡ë³´ ì œê±°!)
    LABEL_MAP_2 = {
        0: ('SELL', -1),
        1: ('BUY', 1)
    }
    
    # 3í´ë˜ìŠ¤ ë ˆì´ë¸” ë§¤í•‘
    LABEL_MAP_3 = {
        0: ('SELL', -1),
        1: ('HOLD', 0),
        2: ('BUY', 1)
    }
    
    # 5í´ë˜ìŠ¤ ë ˆì´ë¸” ë§¤í•‘
    LABEL_MAP_5 = {
        0: ('STRONG_SELL', -2),
        1: ('SELL', -1),
        2: ('HOLD', 0),
        3: ('BUY', 1),
        4: ('STRONG_BUY', 2)
    }
    
    def __init__(
        self,
        model_path: Optional[str] = None,
        scaler_path: Optional[str] = None,
        features_path: Optional[str] = None
    ):
        self.model = None
        self.scaler = None
        self.feature_names = None
        self.is_loaded = False
        self.num_classes = 5  # ê¸°ë³¸ê°’
        
        # ë ˆì´ë¸” ë§¤í•‘ (ëª¨ë¸ ë¡œë“œ ì‹œ ë™ì ìœ¼ë¡œ ì„¤ì •)
        self.label_map = self.LABEL_MAP_5
        
        self.signal_to_simple = {
            'STRONG_SELL': 'SELL',
            'SELL': 'SELL',
            'HOLD': 'HOLD',
            'BUY': 'BUY',
            'STRONG_BUY': 'BUY'
        }
        
        if model_path and scaler_path and features_path:
            self.load_model(model_path, scaler_path, features_path)
    
    def load_model(self, model_path: str, scaler_path: str, features_path: str) -> bool:
        """ëª¨ë¸ ë¡œë“œ"""
        try:
            import joblib
            
            if not os.path.exists(model_path):
                logger.warning(f"Model file not found: {model_path}")
                return False
            
            self.model = joblib.load(model_path)
            self.scaler = joblib.load(scaler_path)
            self.feature_names = joblib.load(features_path)
            self.is_loaded = True
            
            # ëª¨ë¸ì˜ í´ë˜ìŠ¤ ìˆ˜ í™•ì¸
            if hasattr(self.model, 'n_classes_'):
                self.num_classes = self.model.n_classes_
            elif hasattr(self.model, 'classes_'):
                self.num_classes = len(self.model.classes_)
            else:
                self.num_classes = 5  # ê¸°ë³¸ê°’
            
            # í´ë˜ìŠ¤ ìˆ˜ì— ë”°ë¼ ë ˆì´ë¸” ë§¤í•‘ ì„¤ì •
            if self.num_classes == 2:
                self.label_map = self.LABEL_MAP_2
                logger.info(f"   Using 2-class model (SELL/BUY - íš¡ë³´ ì œê±°!)")
            elif self.num_classes == 3:
                self.label_map = self.LABEL_MAP_3
                logger.info(f"   Using 3-class model (SELL/HOLD/BUY)")
            else:
                self.label_map = self.LABEL_MAP_5
                logger.info(f"   Using 5-class model (STRONG_SELL/SELL/HOLD/BUY/STRONG_BUY)")
            
            logger.info(f"âœ… Loaded trained model from {model_path}")
            logger.info(f"   Features: {len(self.feature_names)}, Classes: {self.num_classes}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Failed to load model: {e}")
            self.is_loaded = False
            return False
    
    def predict(self, candles: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        ìº”ë“¤ ë°ì´í„°ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰
        
        Args:
            candles: ìº”ë“¤ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ (ìµœì†Œ 50ê°œ ì´ìƒ ê¶Œì¥)
        
        Returns:
            {
                'signal': 'BUY' | 'SELL' | 'HOLD',
                'detailed_signal': 'STRONG_BUY' | 'BUY' | 'HOLD' | 'SELL' | 'STRONG_SELL',
                'confidence': 0.0 ~ 1.0,
                'probabilities': {...}
            }
        """
        if not self.is_loaded:
            return self._default_response("Model not loaded")
        
        if len(candles) < 50:
            return self._default_response(f"Insufficient data: {len(candles)} candles (min 50)")
        
        try:
            # DataFrame ìƒì„±
            df = pd.DataFrame(candles)
            logger.info(f"ğŸ“Š Input candles: {len(df)}, columns: {df.columns.tolist()[:5]}...")
            
            if 'timestamp' in df.columns:
                df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms', errors='coerce')
                if df['timestamp'].notna().any():
                    df.set_index('timestamp', inplace=True)
            
            # ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
            df = TechnicalIndicators.calculate_all_indicators(df)
            logger.info(f"ğŸ“Š After indicators: {len(df)} rows, columns: {len(df.columns)}")
            
            # ì¶”ê°€ í”¼ì²˜ ìƒì„±
            df = self._create_features(df)
            logger.info(f"ğŸ“Š After features: {len(df)} rows, columns: {len(df.columns)}")
            
            # NaN ì œê±° - ë§ˆì§€ë§‰ í–‰ë§Œ ì‚¬ìš©í•˜ë¯€ë¡œ ë§ˆì§€ë§‰ í–‰ì˜ NaNë§Œ ì²´í¬
            last_row = df.iloc[-1:]
            nan_cols = last_row.columns[last_row.isna().any()].tolist()
            
            if nan_cols:
                logger.warning(f"âš ï¸ NaN columns in last row: {nan_cols[:10]}...")
                # NaN ê°’ì„ 0 ë˜ëŠ” ì´ì „ ê°’ìœ¼ë¡œ ì±„ì›€
                df = df.fillna(method='ffill').fillna(0)
            
            if df.empty:
                return self._default_response("No valid data after processing")
            
            # í”¼ì²˜ ì¶”ì¶œ (ë§ˆì§€ë§‰ í–‰ë§Œ)
            missing_features = [f for f in self.feature_names if f not in df.columns]
            if missing_features:
                logger.warning(f"Missing features: {missing_features}")
                # ì—†ëŠ” í”¼ì²˜ëŠ” 0ìœ¼ë¡œ ì±„ì›€
                for f in missing_features:
                    df[f] = 0
            
            X = df[self.feature_names].iloc[-1:].values
            
            # ì •ê·œí™”
            X_scaled = self.scaler.transform(X)
            
            # ì˜ˆì¸¡
            pred_class = int(self.model.predict(X_scaled)[0])
            pred_proba = self.model.predict_proba(X_scaled)[0]
            
            detailed_signal, signal_value = self.label_map[pred_class]
            simple_signal = self.signal_to_simple[detailed_signal]
            confidence = float(pred_proba[pred_class])
            
            return {
                'signal': simple_signal,
                'detailed_signal': detailed_signal,
                'signal_value': signal_value,
                'confidence': confidence,
                'direction': 'UP' if signal_value > 0 else 'DOWN' if signal_value < 0 else 'NEUTRAL',
                'probabilities': {
                    self.label_map[i][0]: float(p) 
                    for i, p in enumerate(pred_proba)
                },
                'analysis': self._generate_analysis(detailed_signal, confidence, pred_proba)
            }
            
        except Exception as e:
            logger.error(f"âŒ Prediction error: {e}")
            import traceback
            traceback.print_exc()
            return self._default_response(f"Prediction error: {str(e)}")
    
    def _create_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """í†µí•© í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ëª¨ë“ˆ ì‚¬ìš© (í•™ìŠµ/ì¶”ë¡  í”¼ì²˜ ì¼ê´€ì„± ë³´ì¥)"""
        return compute_all_features(df)
    
    def _default_response(self, reason: str) -> Dict[str, Any]:
        """ê¸°ë³¸ ì‘ë‹µ (ì˜ˆì¸¡ ì‹¤íŒ¨ ì‹œ)"""
        return {
            'signal': 'HOLD',
            'detailed_signal': 'HOLD',
            'signal_value': 0,
            'confidence': 0.0,
            'direction': 'NEUTRAL',
            'probabilities': {},
            'analysis': f"Unable to predict: {reason}"
        }
    
    def _generate_analysis(
        self,
        signal: str,
        confidence: float,
        probabilities: np.ndarray
    ) -> str:
        """ë¶„ì„ í…ìŠ¤íŠ¸ ìƒì„± (2í´ë˜ìŠ¤/3í´ë˜ìŠ¤/5í´ë˜ìŠ¤ ëª¨ë¸ ëª¨ë‘ ì§€ì›)"""
        
        # í´ë˜ìŠ¤ ìˆ˜ì— ë”°ë¼ í™•ë¥  ê³„ì‚°
        if len(probabilities) == 2:
            # 2í´ë˜ìŠ¤: SELL(0), BUY(1) - íš¡ë³´ ì œê±°!
            sell_prob = probabilities[0]
            hold_prob = 0  # íš¡ë³´ ì—†ìŒ
            buy_prob = probabilities[1]
        elif len(probabilities) == 3:
            # 3í´ë˜ìŠ¤: SELL(0), HOLD(1), BUY(2)
            sell_prob = probabilities[0]
            hold_prob = probabilities[1]
            buy_prob = probabilities[2]
        elif len(probabilities) == 5:
            # 5í´ë˜ìŠ¤: STRONG_SELL(0), SELL(1), HOLD(2), BUY(3), STRONG_BUY(4)
            sell_prob = probabilities[0] + probabilities[1]
            hold_prob = probabilities[2]
            buy_prob = probabilities[3] + probabilities[4]
        else:
            # ì•Œ ìˆ˜ ì—†ëŠ” í´ë˜ìŠ¤ ìˆ˜
            return f"ì‹ í˜¸: {signal} (ì‹ ë¢°ë„: {confidence*100:.1f}%)"
        
        analysis_parts = []
        
        # ì‹ í˜¸ ì„¤ëª…
        if signal in ['STRONG_BUY', 'BUY']:
            analysis_parts.append(f"ë§¤ìˆ˜ ì‹ í˜¸ ê°ì§€ (ì‹ ë¢°ë„: {confidence*100:.1f}%)")
        elif signal in ['STRONG_SELL', 'SELL']:
            analysis_parts.append(f"ë§¤ë„ ì‹ í˜¸ ê°ì§€ (ì‹ ë¢°ë„: {confidence*100:.1f}%)")
        else:
            analysis_parts.append(f"ê´€ë§ ê¶Œì¥ (ì‹ ë¢°ë„: {confidence*100:.1f}%)")
        
        # í™•ë¥  ë¶„í¬
        analysis_parts.append(
            f"í™•ë¥  ë¶„í¬ - ë§¤ìˆ˜: {buy_prob*100:.1f}%, ê´€ë§: {hold_prob*100:.1f}%, ë§¤ë„: {sell_prob*100:.1f}%"
        )
        
        # ê°•ë„ ì„¤ëª… (5í´ë˜ìŠ¤ ëª¨ë¸ë§Œ)
        if 'STRONG' in signal:
            analysis_parts.append("ê°•í•œ ì‹ í˜¸ì…ë‹ˆë‹¤. í¬ì§€ì…˜ í¬ê¸° ì¡°ì ˆì— ì°¸ê³ í•˜ì„¸ìš”.")
        
        return " | ".join(analysis_parts)


# ì‹¬ë³¼ë³„ ëª¨ë¸ ìºì‹œ
_model_cache: Dict[str, TrainedModelService] = {}


def get_model_dir() -> str:
    """ëª¨ë¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ ë°˜í™˜"""
    current_file = os.path.abspath(__file__)
    services_dir = os.path.dirname(current_file)      # backend/app/services
    app_dir = os.path.dirname(services_dir)           # backend/app
    backend_dir = os.path.dirname(app_dir)            # backend
    project_root = os.path.dirname(backend_dir)       # project root
    model_dir = os.path.join(project_root, 'ai-model', 'models')
    
    # ë””ë²„ê·¸ ë¡œê·¸
    if not hasattr(get_model_dir, '_logged'):
        logger.info(f"ğŸ“ Current file: {current_file}")
        logger.info(f"ğŸ“ Project root: {project_root}")
        logger.info(f"ğŸ“ Model dir: {model_dir}")
        logger.info(f"ğŸ“ Model dir exists: {os.path.exists(model_dir)}")
        if os.path.exists(model_dir):
            files = os.listdir(model_dir)
            logger.info(f"ğŸ“ Model files: {[f for f in files if f.endswith('.joblib') and '_scaler' not in f and '_features' not in f]}")
        get_model_dir._logged = True
    
    return model_dir


def get_available_models() -> List[str]:
    """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ë°˜í™˜"""
    model_dir = get_model_dir()
    if not os.path.exists(model_dir):
        return []
    
    models = []
    for f in os.listdir(model_dir):
        # xgboost_btcusdt_5m_v2.joblib í˜•íƒœì—ì„œ ì‹¬ë³¼ ì¶”ì¶œ
        if f.startswith('xgboost_') and f.endswith('.joblib') and '_scaler' not in f and '_features' not in f:
            # xgboost_btcusdt_5m_v2.joblib -> btcusdt_5m_v2
            model_name = f.replace('xgboost_', '').replace('.joblib', '')
            models.append(model_name)
    
    return models


def find_highest_version_model(symbol: str, timeframe: str) -> Optional[str]:
    """
    ì‹¬ë³¼ê³¼ íƒ€ì„í”„ë ˆì„ì— ë§ëŠ” ê°€ì¥ ë†’ì€ ë²„ì „ì˜ ëª¨ë¸ì„ ì°¾ìŒ
    
    ì˜ˆ: xgboost_btcusdt_5m_v3.joblib > xgboost_btcusdt_5m_v2.joblib > xgboost_btcusdt_5m.joblib
    """
    import re
    
    model_dir = get_model_dir()
    if not os.path.exists(model_dir):
        return None
    
    symbol_lower = symbol.lower()
    pattern = f'xgboost_{symbol_lower}_{timeframe}'
    
    # í•´ë‹¹ ì‹¬ë³¼/íƒ€ì„í”„ë ˆì„ì˜ ëª¨ë“  ëª¨ë¸ íŒŒì¼ ì°¾ê¸°
    matching_models = []
    for f in os.listdir(model_dir):
        if f.startswith(pattern) and f.endswith('.joblib') and '_scaler' not in f and '_features' not in f:
            # ë²„ì „ ë²ˆí˜¸ ì¶”ì¶œ (ì˜ˆ: xgboost_btcusdt_5m_v2.joblib -> 2, xgboost_btcusdt_5m.joblib -> 0)
            version_match = re.search(r'_v(\d+)\.joblib$', f)
            if version_match:
                version = int(version_match.group(1))
            else:
                version = 0  # v ì—†ìœ¼ë©´ ë²„ì „ 0 (v1 ì´ì „)
            
            model_key = f.replace('xgboost_', '').replace('.joblib', '')
            matching_models.append((version, model_key, f))
    
    if not matching_models:
        return None
    
    # ë²„ì „ì´ ê°€ì¥ ë†’ì€ ê²ƒ ì„ íƒ
    matching_models.sort(key=lambda x: x[0], reverse=True)
    best_version, best_model_key, best_file = matching_models[0]
    
    logger.info(f"ğŸ† Found {len(matching_models)} model(s) for {symbol} {timeframe}")
    logger.info(f"   Best: {best_file} (v{best_version})")
    
    return best_model_key


def get_trained_model_service(symbol: str, timeframe: str = '5m') -> TrainedModelService:
    """
    ì‹¬ë³¼ë³„ í•™ìŠµëœ ëª¨ë¸ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜
    ê°€ì¥ ë†’ì€ ë²„ì „ì˜ ëª¨ë¸ì„ ìë™ìœ¼ë¡œ ì„ íƒ
    
    ëª¨ë¸ ëª…ëª… ê·œì¹™: xgboost_{symbol}_{timeframe}_v{N}.joblib
    ì˜ˆ: xgboost_btcusdt_5m_v3.joblib
    """
    # ê°€ì¥ ë†’ì€ ë²„ì „ ëª¨ë¸ ì°¾ê¸°
    model_key = find_highest_version_model(symbol, timeframe)
    
    if not model_key:
        logger.warning(f"âš ï¸ No model found for {symbol} {timeframe}")
        empty_service = TrainedModelService()
        empty_service.is_loaded = False
        return empty_service
    
    # ìºì‹œì— ìˆìœ¼ë©´ ë°˜í™˜
    if model_key in _model_cache:
        cached = _model_cache[model_key]
        if cached.is_loaded:
            return cached
    
    # ëª¨ë¸ ë¡œë“œ
    model_dir = get_model_dir()
    model_name = f'xgboost_{model_key}'
    model_path = os.path.join(model_dir, f'{model_name}.joblib')
    scaler_path = os.path.join(model_dir, f'{model_name}_scaler.joblib')
    features_path = os.path.join(model_dir, f'{model_name}_features.joblib')
    
    service = TrainedModelService()
    if service.load_model(model_path, scaler_path, features_path):
        logger.info(f"âœ… Loaded model for {symbol}: {model_name}")
        _model_cache[model_key] = service
        return service
    
    # ë¡œë“œ ì‹¤íŒ¨
    logger.warning(f"âš ï¸ Failed to load model: {model_name}")
    empty_service = TrainedModelService()
    empty_service.is_loaded = False
    return empty_service


def check_model_exists(symbol: str, timeframe: str = '5m') -> bool:
    """íŠ¹ì • ì‹¬ë³¼ì˜ ëª¨ë¸ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸ (ê°€ì¥ ë†’ì€ ë²„ì „ ê¸°ì¤€)"""
    model_key = find_highest_version_model(symbol, timeframe)
    exists = model_key is not None
    
    logger.info(f"ğŸ” Model check for {symbol} ({timeframe}): {'âœ… Found' if exists else 'âŒ Not found'}")
    
    return exists


# ==================== ì•™ìƒë¸” ëª¨ë¸ ì„œë¹„ìŠ¤ ====================

class EnsembleModelService:
    """XGBoost + LSTM ì•™ìƒë¸” ì˜ˆì¸¡ ì„œë¹„ìŠ¤"""
    
    def __init__(self, symbol: str, timeframe: str = '5m'):
        self.symbol = symbol.upper()
        self.timeframe = timeframe
        self.xgb_service = None
        self.lstm_model = None
        self.lstm_scaler = None
        self.lstm_features = None
        self.lstm_seq_length = 20
        self.is_loaded = False
        
        # ê°€ì¤‘ì¹˜: XGBoostëŠ” ì•ˆì •ì , LSTMì€ íŒ¨í„´ ê°ì§€ì— ê°•í•¨
        self.xgb_weight = 0.6
        self.lstm_weight = 0.4
        
        self._load_models()
    
    def _load_models(self):
        """ëª¨ë¸ë“¤ ë¡œë“œ"""
        import os
        
        model_dir = os.path.join(
            os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(__file__)))),
            'ai-model', 'models'
        )
        
        # 1. XGBoost ëª¨ë¸ ë¡œë“œ
        self.xgb_service = get_trained_model_service(self.symbol, self.timeframe)
        xgb_loaded = self.xgb_service and self.xgb_service.is_loaded
        
        # 2. LSTM ëª¨ë¸ ë¡œë“œ
        lstm_loaded = self._load_lstm(model_dir)
        
        self.is_loaded = xgb_loaded or lstm_loaded
        
        if xgb_loaded and lstm_loaded:
            logger.info(f"ğŸ¯ Ensemble ready: XGBoost + LSTM for {self.symbol}")
        elif xgb_loaded:
            logger.info(f"ğŸ“Š XGBoost only for {self.symbol} (LSTM not found)")
            self.xgb_weight = 1.0
            self.lstm_weight = 0.0
        elif lstm_loaded:
            logger.info(f"ğŸ§  LSTM only for {self.symbol} (XGBoost not found)")
            self.xgb_weight = 0.0
            self.lstm_weight = 1.0
        else:
            logger.warning(f"âš ï¸ No models found for {self.symbol}")
    
    def _load_lstm(self, model_dir: str) -> bool:
        """LSTM ëª¨ë¸ ë¡œë“œ"""
        try:
            import torch
            import joblib
            
            symbol_lower = self.symbol.lower()
            lstm_path = os.path.join(model_dir, f'lstm_{symbol_lower}_{self.timeframe}.pt')
            meta_path = os.path.join(model_dir, f'lstm_{symbol_lower}_{self.timeframe}_meta.joblib')
            
            if not os.path.exists(lstm_path):
                logger.info(f"LSTM model not found: {lstm_path}")
                return False
            
            # ë©”íƒ€ ì •ë³´ ë¡œë“œ
            if os.path.exists(meta_path):
                meta = joblib.load(meta_path)
                self.lstm_scaler = meta.get('scaler')
                self.lstm_features = meta.get('features', self._default_lstm_features())
                self.lstm_seq_length = meta.get('seq_length', 20)
                num_classes = meta.get('num_classes', 3)
            else:
                self.lstm_features = self._default_lstm_features()
                num_classes = 3
            
            # LSTM ëª¨ë¸ ì •ì˜ (BiLSTMClassifier)
            class Attention(torch.nn.Module):
                def __init__(self, hidden_size):
                    super().__init__()
                    self.attention = torch.nn.Sequential(
                        torch.nn.Linear(hidden_size, hidden_size // 2),
                        torch.nn.Tanh(),
                        torch.nn.Linear(hidden_size // 2, 1)
                    )
                
                def forward(self, lstm_output):
                    attention_weights = self.attention(lstm_output)
                    attention_weights = torch.softmax(attention_weights, dim=1)
                    context = torch.sum(lstm_output * attention_weights, dim=1)
                    return context, attention_weights
            
            class BiLSTMClassifier(torch.nn.Module):
                def __init__(self, input_size, hidden_size=64, num_layers=2, num_classes=3, dropout=0.4):
                    super().__init__()
                    self.lstm = torch.nn.LSTM(
                        input_size=input_size, hidden_size=hidden_size,
                        num_layers=num_layers, batch_first=True,
                        bidirectional=True, dropout=dropout if num_layers > 1 else 0
                    )
                    self.attention = Attention(hidden_size * 2)
                    self.bn = torch.nn.BatchNorm1d(hidden_size * 2)
                    self.fc = torch.nn.Sequential(
                        torch.nn.Linear(hidden_size * 2, 64),
                        torch.nn.ReLU(),
                        torch.nn.Dropout(dropout),
                        torch.nn.Linear(64, 32),
                        torch.nn.ReLU(),
                        torch.nn.Dropout(dropout),
                        torch.nn.Linear(32, num_classes)
                    )
                
                def forward(self, x):
                    lstm_out, _ = self.lstm(x)
                    context, _ = self.attention(lstm_out)
                    context = self.bn(context)
                    return self.fc(context)
            
            # ëª¨ë¸ ë¡œë“œ
            input_size = len(self.lstm_features)
            self.lstm_model = BiLSTMClassifier(input_size, num_classes=num_classes)
            self.lstm_model.load_state_dict(torch.load(lstm_path, map_location='cpu'))
            self.lstm_model.eval()
            
            logger.info(f"âœ… LSTM loaded: {lstm_path}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ LSTM load error: {e}")
            return False
    
    def _default_lstm_features(self):
        """ê¸°ë³¸ LSTM í”¼ì²˜ ëª©ë¡ (í†µí•© ëª¨ë“ˆì˜ í•µì‹¬ í”¼ì²˜ ì‚¬ìš©)"""
        from app.services.unified_feature_engineering import get_core_feature_names
        return get_core_feature_names()
    
    def predict(self, candles: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ì•™ìƒë¸” ì˜ˆì¸¡"""
        if not self.is_loaded:
            return self._default_response("No models loaded")
        
        xgb_proba = None
        lstm_proba = None
        
        # 1. XGBoost ì˜ˆì¸¡
        if self.xgb_service and self.xgb_service.is_loaded:
            xgb_result = self.xgb_service.predict(candles)
            if xgb_result.get('confidence', 0) > 0:
                xgb_proba = np.array(list(xgb_result.get('probabilities', {}).values()))
        
        # 2. LSTM ì˜ˆì¸¡
        if self.lstm_model is not None:
            lstm_proba = self._predict_lstm(candles)
        
        # 3. ì•™ìƒë¸”
        if xgb_proba is not None and lstm_proba is not None:
            # í´ë˜ìŠ¤ ìˆ˜ ë§ì¶”ê¸°
            if len(xgb_proba) != len(lstm_proba):
                # ë‹¤ë¥´ë©´ XGBoost ìš°ì„ 
                ensemble_proba = xgb_proba
                model_used = "XGBoost (class mismatch)"
            else:
                ensemble_proba = self.xgb_weight * xgb_proba + self.lstm_weight * lstm_proba
                model_used = f"Ensemble (XGB:{self.xgb_weight:.0%} + LSTM:{self.lstm_weight:.0%})"
        elif xgb_proba is not None:
            ensemble_proba = xgb_proba
            model_used = "XGBoost only"
        elif lstm_proba is not None:
            ensemble_proba = lstm_proba
            model_used = "LSTM only"
        else:
            return self._default_response("Prediction failed")
        
        # 4. ê²°ê³¼ ìƒì„±
        pred_class = int(np.argmax(ensemble_proba))
        confidence = float(ensemble_proba[pred_class])
        
        # ë ˆì´ë¸” ë§¤í•‘ (í´ë˜ìŠ¤ ìˆ˜ì— ë”°ë¼)
        num_classes = len(ensemble_proba)
        if num_classes == 2:
            label_map = {0: ('SELL', -1), 1: ('BUY', 1)}
        elif num_classes == 3:
            label_map = {0: ('SELL', -1), 1: ('HOLD', 0), 2: ('BUY', 1)}
        else:
            label_map = {0: ('STRONG_SELL', -2), 1: ('SELL', -1), 2: ('HOLD', 0), 3: ('BUY', 1), 4: ('STRONG_BUY', 2)}
        
        detailed_signal, signal_value = label_map.get(pred_class, ('HOLD', 0))
        simple_signal = 'BUY' if signal_value > 0 else ('SELL' if signal_value < 0 else 'HOLD')
        
        # í™•ë¥  ë”•ì…”ë„ˆë¦¬
        prob_dict = {label_map[i][0]: float(ensemble_proba[i]) for i in range(len(ensemble_proba))}
        
        # direction ê²°ì •
        direction = 'UP' if signal_value > 0 else ('DOWN' if signal_value < 0 else 'NEUTRAL')
        
        return {
            'signal': simple_signal,
            'detailed_signal': detailed_signal,
            'confidence': confidence,
            'signal_value': signal_value,
            'direction': direction,  # ì¶”ê°€!
            'probabilities': prob_dict,
            'model_used': model_used,
            'analysis': self._generate_analysis(detailed_signal, confidence, ensemble_proba, model_used)
        }
    
    def _predict_lstm(self, candles: List[Dict[str, Any]]) -> Optional[np.ndarray]:
        """LSTM ì˜ˆì¸¡"""
        try:
            import torch
            
            # ë°ì´í„°í”„ë ˆì„ ë³€í™˜
            df = pd.DataFrame(candles)
            
            # ê¸°ìˆ ì  ì§€í‘œ + í†µí•© í”¼ì²˜ ìƒì„±
            df = TechnicalIndicators.calculate_all_indicators(df)
            df = compute_all_features(df)
            
            # í•„ìš”í•œ í”¼ì²˜ë§Œ ì¶”ì¶œ
            available_features = [f for f in self.lstm_features if f in df.columns]
            if len(available_features) < len(self.lstm_features) * 0.5:
                logger.warning("Not enough features for LSTM")
                return None
            
            # NaN ì²˜ë¦¬
            df = df[available_features].fillna(0)
            
            # ì‹œí€€ìŠ¤ ë°ì´í„° ì¤€ë¹„
            if len(df) < self.lstm_seq_length:
                logger.warning(f"Not enough candles for LSTM (need {self.lstm_seq_length})")
                return None
            
            # ë§ˆì§€ë§‰ ì‹œí€€ìŠ¤ ì¶”ì¶œ
            seq_data = df.iloc[-self.lstm_seq_length:].values
            
            # ìŠ¤ì¼€ì¼ë§
            if self.lstm_scaler is not None:
                seq_data = self.lstm_scaler.transform(seq_data)
            
            # í…ì„œ ë³€í™˜
            X = torch.FloatTensor(seq_data).unsqueeze(0)  # (1, seq_len, features)
            
            # ì˜ˆì¸¡
            with torch.no_grad():
                output = self.lstm_model(X)
                proba = torch.softmax(output, dim=1).numpy()[0]
            
            return proba
            
        except Exception as e:
            logger.error(f"LSTM prediction error: {e}")
            return None
    
    def _generate_analysis(self, signal: str, confidence: float, proba: np.ndarray, model_used: str) -> str:
        """ë¶„ì„ í…ìŠ¤íŠ¸ ìƒì„±"""
        parts = []
        
        parts.append(f"ğŸ¯ {model_used}")
        
        if signal in ['BUY', 'STRONG_BUY']:
            parts.append(f"ğŸ“ˆ ë§¤ìˆ˜ ì‹ í˜¸ (ì‹ ë¢°ë„: {confidence*100:.1f}%)")
        elif signal in ['SELL', 'STRONG_SELL']:
            parts.append(f"ğŸ“‰ ë§¤ë„ ì‹ í˜¸ (ì‹ ë¢°ë„: {confidence*100:.1f}%)")
        else:
            parts.append(f"â¸ï¸ ê´€ë§ (ì‹ ë¢°ë„: {confidence*100:.1f}%)")
        
        # í™•ë¥  ë¶„í¬
        if len(proba) == 2:
            parts.append(f"í™•ë¥ : BUY {proba[1]*100:.1f}% / SELL {proba[0]*100:.1f}%")
        elif len(proba) == 3:
            parts.append(f"í™•ë¥ : BUY {proba[2]*100:.1f}% / HOLD {proba[1]*100:.1f}% / SELL {proba[0]*100:.1f}%")
        
        return " | ".join(parts)
    
    def _default_response(self, reason: str) -> Dict[str, Any]:
        """ê¸°ë³¸ ì‘ë‹µ"""
        return {
            'signal': 'HOLD',
            'detailed_signal': 'HOLD',
            'confidence': 0.0,
            'signal_value': 0,
            'direction': 'NEUTRAL',  # ì¶”ê°€!
            'probabilities': {'HOLD': 1.0},
            'model_used': 'None',
            'analysis': f"âš ï¸ {reason}"
        }


# ì•™ìƒë¸” ì„œë¹„ìŠ¤ ìºì‹œ
_ensemble_cache: Dict[str, EnsembleModelService] = {}


def get_ensemble_service(symbol: str, timeframe: str = '5m') -> EnsembleModelService:
    """ì•™ìƒë¸” ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸° (ìºì‹œ)"""
    cache_key = f"{symbol.upper()}_{timeframe}"
    
    if cache_key not in _ensemble_cache:
        _ensemble_cache[cache_key] = EnsembleModelService(symbol, timeframe)
    
    return _ensemble_cache[cache_key]

